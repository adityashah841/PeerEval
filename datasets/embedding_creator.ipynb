{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "! pip install fuzzywuzzy summa transformers sentencepiece nltk chardet"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VTqut9ilpOo9",
        "outputId": "b6fa59e3-1c8a-4d5d-f15c-7723f010f6de"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: fuzzywuzzy in /usr/local/lib/python3.10/dist-packages (0.18.0)\n",
            "Requirement already satisfied: summa in /usr/local/lib/python3.10/dist-packages (1.2.0)\n",
            "Requirement already satisfied: transformers in /usr/local/lib/python3.10/dist-packages (4.35.2)\n",
            "Requirement already satisfied: sentencepiece in /usr/local/lib/python3.10/dist-packages (0.1.99)\n",
            "Requirement already satisfied: nltk in /usr/local/lib/python3.10/dist-packages (3.8.1)\n",
            "Requirement already satisfied: chardet in /usr/local/lib/python3.10/dist-packages (5.2.0)\n",
            "Requirement already satisfied: scipy>=0.19 in /usr/local/lib/python3.10/dist-packages (from summa) (1.11.4)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from transformers) (3.13.1)\n",
            "Requirement already satisfied: huggingface-hub<1.0,>=0.16.4 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.19.4)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/dist-packages (from transformers) (1.23.5)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from transformers) (23.2)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from transformers) (6.0.1)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.10/dist-packages (from transformers) (2023.6.3)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from transformers) (2.31.0)\n",
            "Requirement already satisfied: tokenizers<0.19,>=0.14 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.15.0)\n",
            "Requirement already satisfied: safetensors>=0.3.1 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.4.1)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.10/dist-packages (from transformers) (4.66.1)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.10/dist-packages (from nltk) (8.1.7)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.10/dist-packages (from nltk) (1.3.2)\n",
            "Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.16.4->transformers) (2023.6.0)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.16.4->transformers) (4.5.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (3.6)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (2023.11.17)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install python-Levenshtein"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "50WNmDegpiGm",
        "outputId": "b76d0566-fe57-4ef5-f0a9-0d7334500bed"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: python-Levenshtein in /usr/local/lib/python3.10/dist-packages (0.23.0)\n",
            "Requirement already satisfied: Levenshtein==0.23.0 in /usr/local/lib/python3.10/dist-packages (from python-Levenshtein) (0.23.0)\n",
            "Requirement already satisfied: rapidfuzz<4.0.0,>=3.1.0 in /usr/local/lib/python3.10/dist-packages (from Levenshtein==0.23.0->python-Levenshtein) (3.5.2)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "\n",
        "drive.mount(\"/content/drive\")"
      ],
      "metadata": {
        "id": "MmnEf3Zzqu3O",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "6074901b-387a-417a-b532-75a55184d13f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "base_dir = \"/content/drive/My Drive\""
      ],
      "metadata": {
        "id": "5O36AcJNq-VG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# !unzip \"/content/drive/My Drive/ICLR_2018-20230920T071401Z-001\" -d \"/content/drive/My Drive\"\n",
        "# !unzip \"/content/drive/My Drive/ICLR_2018\" -d \"/content/drive/My Drive\""
      ],
      "metadata": {
        "id": "GHfywch-rFVK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Wmn-9NCZotuZ"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "from torch.utils.data import DataLoader, TensorDataset\n",
        "from fuzzywuzzy import fuzz\n",
        "from fuzzywuzzy import process\n",
        "# from summa.summarizer import summarize\n",
        "import torch\n",
        "from transformers import AutoTokenizer, AutoModel\n",
        "import transformers\n",
        "from nltk.tokenize import sent_tokenize\n",
        "import json\n",
        "import pickle as pkl\n",
        "import os\n",
        "import pandas as pd\n",
        "import chardet"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')"
      ],
      "metadata": {
        "id": "RG4ICRspGKrG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "tokenizer = AutoTokenizer.from_pretrained(\"allenai/scibert_scivocab_uncased\")\n",
        "model = AutoModel.from_pretrained(\"allenai/scibert_scivocab_uncased\").to(device)"
      ],
      "metadata": {
        "id": "L2h2xBORpLNf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model1 = transformers.PegasusForConditionalGeneration.from_pretrained(\"google/pegasus-xsum\").to(device)\n",
        "tokenizer1 = transformers.PegasusTokenizer.from_pretrained(\"google/pegasus-xsum\")"
      ],
      "metadata": {
        "id": "6x7AKGMb8zdL",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "3b42e1fb-0b51-4238-df17-141333e72697"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some weights of PegasusForConditionalGeneration were not initialized from the model checkpoint at google/pegasus-xsum and are newly initialized: ['model.encoder.embed_positions.weight', 'model.decoder.embed_positions.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def get_encoding(file):\n",
        "    with open(file, 'rb') as f:\n",
        "        result = chardet.detect(f.read())\n",
        "        # print(result[\"encoding\"])\n",
        "    return result['encoding']\n",
        "\n",
        "def read_json(file_path):\n",
        "    with open(file_path, 'rb') as file:\n",
        "        data = file.read().decode('utf-8-sig')\n",
        "        data = json.loads(data)\n",
        "    return data"
      ],
      "metadata": {
        "id": "NnYCMaO6poQP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def summarize(txt):\n",
        "    chunk_size = 300\n",
        "    input_chunks = [txt[i:i + chunk_size] for i in range(0, len(txt), chunk_size)]\n",
        "    summaries = []\n",
        "    for chunk in input_chunks:\n",
        "        input_ids = tokenizer1.encode(chunk, return_tensors=\"pt\", max_length=1024, truncation=True).to(device)\n",
        "        summary_ids = model1.generate(input_ids, max_length=30, min_length=20, length_penalty=2.0, num_beams=4, early_stopping=True)\n",
        "        summary_text = tokenizer1.decode(summary_ids[0], skip_special_tokens=True)\n",
        "        summaries.append(summary_text)\n",
        "    final_summary = \" \".join(summaries)\n",
        "    return final_summary"
      ],
      "metadata": {
        "id": "PjJ0Gvdh8u5j"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def paper_tokenization(paper_path):\n",
        "    json_data = read_json(paper_path)\n",
        "    # l=json_data['metadata']['sections']\n",
        "    if 'sections' not in json_data:\n",
        "        return None\n",
        "    l = json_data['sections']\n",
        "    sections=['abstract', 'introduction', 'related works', 'problem definition', 'idea', 'methodology', 'experiments', 'results', 'tables & figures', 'analysis', 'future work', 'overall', 'bibliography', 'external']\n",
        "    d={}\n",
        "    count_no_head = 0\n",
        "    summary = ''\n",
        "    for section in l:\n",
        "        txt = section['text']\n",
        "        summary_txt=txt\n",
        "        while len(summary_txt.split())>200:\n",
        "            summary_txt = summarize(summary_txt)\n",
        "        summary += summary_txt\n",
        "\n",
        "    final_summary = summary\n",
        "    # while len(final_summary.split())>250:\n",
        "    #     final_summary=summarize(final_summary)\n",
        "    print(len(final_summary))\n",
        "    tokens = tokenizer.tokenize(final_summary)\n",
        "    token_ids = tokenizer.convert_tokens_to_ids(tokens)\n",
        "    input_ids = tokenizer.encode(final_summary, max_length=512, add_special_tokens=True, truncation=True, padding='max_length')\n",
        "    input_ids = torch.tensor(input_ids).to(device)\n",
        "    attention_mask = (input_ids != tokenizer.pad_token_id).long()\n",
        "    input_ids = input_ids.unsqueeze(0)\n",
        "    print(input_ids.shape)\n",
        "    attention_mask = attention_mask.unsqueeze(0)\n",
        "    outputs = model(input_ids, attention_mask=attention_mask)\n",
        "    sentence_embeddings = outputs[0].squeeze()\n",
        "    # d[k]=sentence_embeddings\n",
        "    print(f\"Paper embedding shape: {sentence_embeddings.shape}\")\n",
        "    # del sentence_embeddings\n",
        "    del outputs\n",
        "    del input_ids\n",
        "    del token_ids\n",
        "    del tokens\n",
        "    del l\n",
        "    del json_data\n",
        "    return sentence_embeddings"
      ],
      "metadata": {
        "id": "lZSBPJASprui"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def review_tokenizer(review_path):\n",
        "    with open(review_path, \"r\", encoding=get_encoding(review_path)) as file:\n",
        "        content = file.read()\n",
        "\n",
        "    tokens = tokenizer.tokenize(content)\n",
        "    token_ids = tokenizer.convert_tokens_to_ids(tokens)\n",
        "    input_ids = tokenizer.encode(content, add_special_tokens=True, max_length=512, truncation=True, padding='max_length')\n",
        "    # Create the attention mask\n",
        "    input_ids = torch.tensor(input_ids).to(device)\n",
        "    attention_mask = (input_ids != tokenizer.pad_token_id).long()\n",
        "    # input_ids, attention_mask = tokenizer.pad(input_ids, padding='max_length', max_length=512, return_tensors='pt', return_attention_mask=True)\n",
        "    input_ids = input_ids.unsqueeze(0)\n",
        "    attention_mask = attention_mask.unsqueeze(0)\n",
        "    outputs = model(input_ids, attention_mask=attention_mask)\n",
        "    sentence_embeddings = outputs[0].squeeze()\n",
        "    print(f\"Review embedding shape: {sentence_embeddings.shape}\")\n",
        "    del outputs\n",
        "    del input_ids\n",
        "    del token_ids\n",
        "    del tokens\n",
        "    del content\n",
        "    del file\n",
        "    return sentence_embeddings"
      ],
      "metadata": {
        "id": "oXK7H1BfqQS4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "final_papers = {\n",
        "   'paper_name': [],\n",
        "   'tokenized_paper': [],\n",
        "   'tokenized_reviews': []\n",
        "}\n",
        "# with open(os.path.join(base_dir, 'embeddings_ICLR_2018.pkl'), 'rb') as fr:\n",
        "#    final_papers = pkl.load(fr)"
      ],
      "metadata": {
        "id": "VVQczwSpqc8A"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"Completed paper names:\")\n",
        "print(final_papers['paper_name'])\n",
        "\n",
        "# init_path='Complete_Dataset'\n",
        "# init_path = ''\n",
        "# years = os.listdir(init_path)\n",
        "years = [\"ICLR_2018\"]\n",
        "# Change batch size as per your laptop's capacity\n",
        "batch_size = 25\n",
        "# This n is for self, to remember which iteration is going on, how many more are remaining, etc. Not used in code explicitly\n",
        "n = 1\n",
        "\n",
        "df = pd.read_csv(os.path.join(base_dir, \"data_latest_final2.csv\"))"
      ],
      "metadata": {
        "id": "hxGWWWy9qXLh",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "5b6638e9-c338-4998-c64b-2965b29f35b9"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Completed paper names:\n",
            "[]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# import pickle\n",
        "\n",
        "# filename = 'embeddings_ICLR_2018_test1.pkl'\n",
        "\n",
        "# with open(filename, 'wb') as file:\n",
        "#     pickle.dump(final_papers, file)"
      ],
      "metadata": {
        "id": "pUc__DNZZUvM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# final_papers = {\n",
        "#    'paper_name': [],\n",
        "#    'tokenized_paper': [],\n",
        "#    'tokenized_reviews': []\n",
        "# }\n",
        "with open(os.path.join(base_dir, 'embeddings_ICLR_2018_test1.pkl'), 'rb') as fr:\n",
        "   final_papers = pkl.load(fr)\n",
        "\n",
        "print(\"Completed paper names:\")\n",
        "print(final_papers['paper_name'])\n",
        "\n",
        "# init_path='Complete_Dataset'\n",
        "# init_path = ''\n",
        "# years = os.listdir(init_path)\n",
        "years = [\"ICLR_2018\"]\n",
        "# Change batch size as per your laptop's capacity\n",
        "batch_size = 6\n",
        "# This n is for self, to remember which iteration is going on, how many more are remaining, etc. Not used in code explicitly\n",
        "n = 53\n",
        "#n=52 is over\n",
        "\n",
        "df = pd.read_csv(os.path.join(base_dir, \"data_latest_final2.csv\"))\n",
        "\n",
        "for year in years:\n",
        "    path2 = os.path.join(base_dir, year)\n",
        "    acceptance_list = os.listdir(path2)\n",
        "    # for cat in acceptance_list:\n",
        "    # Change this list when required\n",
        "    for cat in [\"Poster_Papers\"]:\n",
        "    # for cat in [\"Rejected_Papers\"]:\n",
        "        path3 = os.path.join(path2, cat)\n",
        "        papers = os.listdir(path3)\n",
        "        papers.sort()\n",
        "        # You will have to change indices here, based on number of papers in a folder.\n",
        "        batch_papers = papers[batch_size * n : batch_size * n + batch_size]\n",
        "        print(f\"Current ID range {batch_size * n} to {batch_size * n + batch_size - 1}\")\n",
        "        # For last batch, you can use the following commented line and put appropriate indices\n",
        "        # batch_papers = papers[495:496]\n",
        "        for paper in batch_papers:\n",
        "            print(f\"\\nCurrent Paper: {paper}\")\n",
        "            path4 = os.path.join(path3, paper)\n",
        "            docs = os.listdir(path4)\n",
        "            reviews = []\n",
        "            count_pdf = len([x for x in docs if x[-4:] == '.pdf'])\n",
        "            # Here, the metadata (Science Parse) file is used (I had named it {some text here}_new_metadata.json)\n",
        "            count_json = len([x for x in docs if x[-17:] == 'new_metadata.json'])\n",
        "            review_original_old = [f\"{year}_{cat}_{paper}_({x})\" for x in docs if x[-4:] == '.txt' and not x.__contains__(\"MetaReview\")]\n",
        "            review_original = []\n",
        "            for name in review_original_old:\n",
        "                name_tmp = name\n",
        "                row = df[df[\"paper_name\"].str.contains(name_tmp.split('(')[1][:-5])]\n",
        "                if not row.empty:\n",
        "                    review_original.append(name)\n",
        "            count_txt = len(review_original)\n",
        "            if count_json != 0 and count_txt != 0:\n",
        "                for doc in docs:\n",
        "                    if doc[-17:] == 'new_metadata.json':\n",
        "                        tokenized_paper = paper_tokenization(os.path.join(path4, doc))\n",
        "                    # if doc[-4:] == '.txt':\n",
        "                        # tokenized_review = review_tokenizer(path4 + '/' + doc)\n",
        "                        # reviews.append(tokenized_review)\n",
        "                for review in review_original:\n",
        "                  #  tokenized_review = review_tokenizer(path4 + '/' + review.split('(')[1][:-1])\n",
        "                   print(f\"Current review: {review}\")\n",
        "                   tokenized_review = review_tokenizer(os.path.join(path4, review.split('(')[1][:-1]))\n",
        "                   reviews.append(tokenized_review)\n",
        "                if tokenized_paper != None:\n",
        "                  final_papers['paper_name'].append(f\"{year}_{cat}_{paper}\")\n",
        "                  # final_papers['review_names'].append(review_original)\n",
        "                  final_papers['tokenized_paper'].append(tokenized_paper)\n",
        "                  # reviews = torch.stack(reviews)\n",
        "                  # final_papers['tokenized_reviews'].append(reviews)\n",
        "                  final_papers['tokenized_reviews'].append([(x, y) for x, y in zip(review_original, reviews)])\n",
        "                  print(f\"Completed {paper}\")\n",
        "                else:\n",
        "                  print(f\"Not Completed {paper}\")\n",
        "                del tokenized_paper\n",
        "                del tokenized_review\n",
        "            else:\n",
        "               print(f\"{paper} not available in csv\")\n",
        "            del review_original\n",
        "            del docs\n",
        "            del reviews\n",
        "        del batch_papers\n",
        "        del papers\n",
        "    print(year)\n",
        "\n",
        "with open(os.path.join(base_dir, 'embeddings_ICLR_2018_test1.pkl'), 'wb') as f:\n",
        "    pkl.dump(final_papers, f)"
      ],
      "metadata": {
        "id": "iy-8EYqyqffO",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ad39b157-ca6b-4183-9778-f75de1d287a5"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Completed paper names:\n",
            "['ICLR_2018_Rejected_Papers_B13EC5u6W', 'ICLR_2018_Rejected_Papers_B16_iGWCW', 'ICLR_2018_Rejected_Papers_B16yEqkCZ', 'ICLR_2018_Rejected_Papers_B1CEaMbR-', 'ICLR_2018_Rejected_Papers_B1CNpYg0-', 'ICLR_2018_Rejected_Papers_B1CQGfZ0b', 'ICLR_2018_Rejected_Papers_B1D6ty-A-', 'ICLR_2018_Rejected_Papers_B1EGg7ZCb', 'ICLR_2018_Rejected_Papers_B1EPYJ-C-', 'ICLR_2018_Rejected_Papers_B1EVwkqTW', 'ICLR_2018_Rejected_Papers_B1KFAGWAZ', 'ICLR_2018_Rejected_Papers_B1NGT8xCZ', 'ICLR_2018_Rejected_Papers_B1NOXfWR-', 'ICLR_2018_Rejected_Papers_B1X4DWWRb', 'ICLR_2018_Rejected_Papers_B1ZZTfZAW', 'ICLR_2018_Rejected_Papers_B1bgpzZAZ', 'ICLR_2018_Rejected_Papers_B1i7ezW0-', 'ICLR_2018_Rejected_Papers_B1kIr-WRb', 'ICLR_2018_Rejected_Papers_B1mAkPxCZ', 'ICLR_2018_Rejected_Papers_B1mSWUxR-', 'ICLR_2018_Rejected_Papers_B1nLkl-0Z', 'ICLR_2018_Rejected_Papers_B1nxTzbRZ', 'ICLR_2018_Rejected_Papers_B1spAqUp-', 'ICLR_2018_Rejected_Papers_B1suU-bAW', 'ICLR_2018_Rejected_Papers_B1tC-LT6W', 'ICLR_2018_Rejected_Papers_B1tExikAW', 'ICLR_2018_Rejected_Papers_B1twdMCab', 'ICLR_2018_Rejected_Papers_B1uvH_gC-', 'ICLR_2018_Rejected_Papers_B1ydPgTpW', 'ICLR_2018_Rejected_Papers_B1suU-bAW', 'ICLR_2018_Rejected_Papers_B1tC-LT6W', 'ICLR_2018_Rejected_Papers_B1tExikAW', 'ICLR_2018_Rejected_Papers_B1twdMCab', 'ICLR_2018_Rejected_Papers_B1uvH_gC-', 'ICLR_2018_Rejected_Papers_B1ydPgTpW', 'ICLR_2018_Rejected_Papers_BJ4prNx0W', 'ICLR_2018_Rejected_Papers_BJ6anzb0Z', 'ICLR_2018_Rejected_Papers_BJ78bJZCZ', 'ICLR_2018_Rejected_Papers_BJ7d0fW0b', 'ICLR_2018_Rejected_Papers_BJB7fkWR-', 'ICLR_2018_Rejected_Papers_BJDEbngCZ', 'ICLR_2018_Rejected_Papers_BJDH5M-AW', 'ICLR_2018_Rejected_Papers_BJInMmWC-', 'ICLR_2018_Rejected_Papers_BJLmN8xRW', 'ICLR_2018_Rejected_Papers_BJMuY-gRW', 'ICLR_2018_Rejected_Papers_BJQPG5lR-', 'ICLR_2018_Rejected_Papers_BJRxfZbAW', 'ICLR_2018_Rejected_Papers_BJ_QxP1AZ', 'ICLR_2018_Rejected_Papers_BJaU__eCZ', 'ICLR_2018_Rejected_Papers_BJcAWaeCW', 'ICLR_2018_Rejected_Papers_BJgPCveAW', 'ICLR_2018_Rejected_Papers_BJgVaG-Ab', 'ICLR_2018_Rejected_Papers_BJgd7m0xRZ', 'ICLR_2018_Rejected_Papers_BJhxcGZCW', 'ICLR_2018_Rejected_Papers_BJjBnN9a-', 'ICLR_2018_Rejected_Papers_BJlrSmbAZ', 'ICLR_2018_Rejected_Papers_BJluxbWC-', 'ICLR_2018_Rejected_Papers_BJvVbCJCb', 'ICLR_2018_Rejected_Papers_BJvWjcgAZ', 'ICLR_2018_Rejected_Papers_Bk-ofQZRb', 'ICLR_2018_Rejected_Papers_Bk346Ok0W', 'ICLR_2018_Rejected_Papers_Bk6qQGWRb', 'ICLR_2018_Rejected_Papers_Bk7wvW-C-', 'ICLR_2018_Rejected_Papers_BkDB51WR-', 'ICLR_2018_Rejected_Papers_BkIkkseAZ', 'ICLR_2018_Rejected_Papers_BkM27IxR-', 'ICLR_2018_Rejected_Papers_BkPrDFgR-', 'ICLR_2018_Rejected_Papers_BkQCGzZ0-', 'ICLR_2018_Rejected_Papers_BkS3fnl0W', 'ICLR_2018_Rejected_Papers_BkUDW_lCb', 'ICLR_2018_Rejected_Papers_BkVf1AeAZ', 'ICLR_2018_Rejected_Papers_BkVsWbbAW', 'ICLR_2018_Rejected_Papers_Bk_fs6gA-', 'ICLR_2018_Rejected_Papers_BkeC_J-R-', 'ICLR_2018_Rejected_Papers_Bki1Ct1AW', 'ICLR_2018_Rejected_Papers_BkiIkBJ0b', 'ICLR_2018_Rejected_Papers_Bkl1uWb0Z', 'ICLR_2018_Rejected_Papers_BkoCeqgR-', 'ICLR_2018_Rejected_Papers_BkpXqwUTZ', 'ICLR_2018_Rejected_Papers_By-IifZRW', 'ICLR_2018_Rejected_Papers_By0ANxbRW', 'ICLR_2018_Rejected_Papers_By3VrbbAb', 'ICLR_2018_Rejected_Papers_By5SY2gA-', 'ICLR_2018_Rejected_Papers_By5ugjyCb', 'ICLR_2018_Rejected_Papers_By9iRkWA-', 'ICLR_2018_Rejected_Papers_ByCPHrgCW', 'ICLR_2018_Rejected_Papers_ByED-X-0W', 'ICLR_2018_Rejected_Papers_ByJ7obb0b', 'ICLR_2018_Rejected_Papers_ByJDAIe0b', 'ICLR_2018_Rejected_Papers_ByJbJwxCW', 'ICLR_2018_Rejected_Papers_ByL48G-AW', 'ICLR_2018_Rejected_Papers_ByUEelW0-', 'ICLR_2018_Rejected_Papers_ByW5yxgA-', 'ICLR_2018_Rejected_Papers_ByYPLJA6W', 'ICLR_2018_Rejected_Papers_ByZmGjkA-', 'ICLR_2018_Rejected_Papers_Byht0GbRZ', 'ICLR_2018_Rejected_Papers_ByhthReRb', 'ICLR_2018_Rejected_Papers_Byk4My-RZ', 'ICLR_2018_Rejected_Papers_Bym0cU1CZ', 'ICLR_2018_Rejected_Papers_ByqFhGZCW', 'ICLR_2018_Rejected_Papers_ByquB-WC-', 'ICLR_2018_Rejected_Papers_Bys_NzbC-', 'ICLR_2018_Rejected_Papers_ByuI-mW0W', 'ICLR_2018_Rejected_Papers_ByuP8yZRb', 'ICLR_2018_Rejected_Papers_ByzvHagA-', 'ICLR_2018_Rejected_Papers_H1-oTz-Cb', 'ICLR_2018_Rejected_Papers_H113pWZRb', 'ICLR_2018_Rejected_Papers_H139Q_gAW', 'ICLR_2018_Rejected_Papers_H13WofbAb', 'ICLR_2018_Rejected_Papers_H15RufWAW', 'ICLR_2018_Rejected_Papers_H18uzzWAZ', 'ICLR_2018_Rejected_Papers_H1A5ztj3b', 'ICLR_2018_Rejected_Papers_H1BHbmWCZ', 'ICLR_2018_Rejected_Papers_H1BO9M-0Z', 'ICLR_2018_Rejected_Papers_H1DGha1CZ', 'ICLR_2018_Rejected_Papers_H1DJFybC-', 'ICLR_2018_Rejected_Papers_H1K6Tb-AZ', 'ICLR_2018_Rejected_Papers_H1LAqMbRW', 'ICLR_2018_Rejected_Papers_H1Nyf7W0Z', 'ICLR_2018_Rejected_Papers_H1O0KGC6b', 'ICLR_2018_Rejected_Papers_H1OQukZ0-', 'ICLR_2018_Rejected_Papers_H1U_af-0-', 'ICLR_2018_Rejected_Papers_H1Ww66x0-', 'ICLR_2018_Rejected_Papers_H1a37GWCZ', 'ICLR_2018_Rejected_Papers_H1bM1fZCW', 'ICLR_2018_Rejected_Papers_H1bhRHeA-', 'ICLR_2018_Rejected_Papers_H1kMMmb0-', 'ICLR_2018_Rejected_Papers_H1l8sz-AW', 'ICLR_2018_Rejected_Papers_H1pri9vTZ', 'ICLR_2018_Rejected_Papers_H1srNebAZ', 'ICLR_2018_Rejected_Papers_H1u8fMW0b', 'ICLR_2018_Rejected_Papers_H1uP7ebAW', 'ICLR_2018_Rejected_Papers_H1vCXOe0b', 'ICLR_2018_Rejected_Papers_H1wt9x-RW', 'ICLR_2018_Rejected_Papers_H1xJjlbAZ', 'ICLR_2018_Rejected_Papers_HJ1HFlZAb', 'ICLR_2018_Rejected_Papers_HJ4IhxZAb', 'ICLR_2018_Rejected_Papers_HJ4YGZ-AW', 'ICLR_2018_Rejected_Papers_HJ5AUm-CZ', 'ICLR_2018_Rejected_Papers_HJ8W1Q-0Z', 'ICLR_2018_Rejected_Papers_HJBhEMbRb', 'ICLR_2018_Rejected_Papers_HJDUjKeA-', 'ICLR_2018_Rejected_Papers_HJDV5YxCW', 'ICLR_2018_Rejected_Papers_HJGcNz-0W', 'ICLR_2018_Rejected_Papers_HJIhGXWCZ', 'ICLR_2018_Rejected_Papers_HJMN-xWC-', 'ICLR_2018_Rejected_Papers_HJNGGmZ0Z', 'ICLR_2018_Rejected_Papers_HJOQ7MgAW', 'ICLR_2018_Rejected_Papers_HJRV1ZZAW', 'ICLR_2018_Rejected_Papers_HJZiRkZC-', 'ICLR_2018_Rejected_Papers_HJcjQTJ0W', 'ICLR_2018_Rejected_Papers_HJdXGy1RW', 'ICLR_2018_Rejected_Papers_HJg1NTGZRZ', 'ICLR_2018_Rejected_Papers_HJjePwx0-', 'ICLR_2018_Rejected_Papers_HJqUtdOaZ', 'ICLR_2018_Rejected_Papers_HJr4QJ26W', 'ICLR_2018_Rejected_Papers_HJrJpzZRZ', 'ICLR_2018_Rejected_Papers_HJsk5-Z0W', 'ICLR_2018_Rejected_Papers_Hk-FlMbAZ', 'ICLR_2018_Rejected_Papers_Hk2MHt-3-', 'ICLR_2018_Rejected_Papers_HkCvZXbC-', 'ICLR_2018_Rejected_Papers_HkGcX--0-', 'ICLR_2018_Rejected_Papers_HkJ1rgbCb', 'ICLR_2018_Rejected_Papers_HkMCybx0-', 'ICLR_2018_Rejected_Papers_HkMhoDITb', 'ICLR_2018_Rejected_Papers_HkOhuyA6-', 'ICLR_2018_Rejected_Papers_HkPCrEZ0Z', 'ICLR_2018_Rejected_Papers_Hk__kGbCW', 'ICLR_2018_Rejected_Papers_HkanP0lRW', 'ICLR_2018_Rejected_Papers_HkbJTYyAb', 'ICLR_2018_Rejected_Papers_HkbmWqxCZ', 'ICLR_2018_Rejected_Papers_HkeJVllRW', 'ICLR_2018_Rejected_Papers_HkepKG-Rb', 'ICLR_2018_Rejected_Papers_Hki-ZlbA-', 'ICLR_2018_Rejected_Papers_HkinqfbAb', 'ICLR_2018_Rejected_Papers_HkjL6MiTb', 'ICLR_2018_Rejected_Papers_HklZOfW0W', 'ICLR_2018_Rejected_Papers_HklpCzC6-', 'ICLR_2018_Rejected_Papers_HknbyQbC-', 'ICLR_2018_Rejected_Papers_Hkp3uhxCW', 'ICLR_2018_Rejected_Papers_HkpRBFxRb', 'ICLR_2018_Rejected_Papers_HktXuGb0-', 'ICLR_2018_Rejected_Papers_HkwrqtlR-', 'ICLR_2018_Rejected_Papers_Hy3MvSlRW', 'ICLR_2018_Rejected_Papers_Hy8hkYeRb', 'ICLR_2018_Rejected_Papers_HyBbjW-RW', 'ICLR_2018_Rejected_Papers_HyDAQl-AW', 'ICLR_2018_Rejected_Papers_HyEi7bWR-', 'ICLR_2018_Rejected_Papers_HyFaiGbCW', 'ICLR_2018_Rejected_Papers_HyHmGyZCZ', 'ICLR_2018_Rejected_Papers_HyI5ro0pW', 'ICLR_2018_Rejected_Papers_HyI6s40a-', 'ICLR_2018_Rejected_Papers_HyKZyYlRZ', 'ICLR_2018_Rejected_Papers_HyN-ZvlC-', 'ICLR_2018_Rejected_Papers_HyPpD0g0Z', 'ICLR_2018_Rejected_Papers_HyTrSegCb', 'ICLR_2018_Rejected_Papers_HyXBcYg0b', 'ICLR_2018_Rejected_Papers_Hy_o3x-0b', 'ICLR_2018_Rejected_Papers_HydnA1WCb', 'ICLR_2018_Rejected_Papers_Hyig0zb0Z', 'ICLR_2018_Rejected_Papers_HylgYB3pZ', 'ICLR_2018_Rejected_Papers_HymYLebCb', 'ICLR_2018_Rejected_Papers_Hyp-JJJRW', 'ICLR_2018_Rejected_Papers_Hyp3i2xRb', 'ICLR_2018_Rejected_Papers_HytSvlWRZ', 'ICLR_2018_Rejected_Papers_SkYXvCR6W', 'ICLR_2018_Rejected_Papers_Sy-tszZRZ', 'ICLR_2018_Rejected_Papers_Sy1f0e-R-', 'ICLR_2018_Rejected_Papers_Sy3fJXbA-', 'ICLR_2018_Rejected_Papers_SyGT_6yCZ', 'ICLR_2018_Rejected_Papers_SyL9u-WA-', 'ICLR_2018_Rejected_Papers_SySisz-CW', 'ICLR_2018_Rejected_Papers_SyXNErg0W', 'ICLR_2018_Rejected_Papers_SyhcXjy0Z', 'ICLR_2018_Rejected_Papers_SyjsLqxR-', 'ICLR_2018_Rejected_Papers_SyrGJYlRZ', 'ICLR_2018_Rejected_Papers_Syt0r4bRZ', 'ICLR_2018_Poster_Papers_B12Js_yRb', 'ICLR_2018_Poster_Papers_B13njo1R-', 'ICLR_2018_Poster_Papers_B14TlG-RW', 'ICLR_2018_Poster_Papers_B17JTOe0-', 'ICLR_2018_Poster_Papers_B1DmUzWAW', 'ICLR_2018_Poster_Papers_B1EA-M-0Z', 'ICLR_2018_Poster_Papers_B1Gi6LeRZ', 'ICLR_2018_Poster_Papers_B1IDRdeCW', 'ICLR_2018_Poster_Papers_B1J_rgWRW', 'ICLR_2018_Poster_Papers_B1Lc-Gb0Z', 'ICLR_2018_Poster_Papers_B1QgVti6Z', 'ICLR_2018_Poster_Papers_B1X0mzZCW', 'ICLR_2018_Poster_Papers_B1Yy1BxCZ', 'ICLR_2018_Poster_Papers_B1ZvaaeAZ', 'ICLR_2018_Poster_Papers_B1ae1lZRb', 'ICLR_2018_Poster_Papers_B1al7jg0b', 'ICLR_2018_Poster_Papers_B1e5ef-C-', 'ICLR_2018_Poster_Papers_B1hYRMbCW', 'ICLR_2018_Poster_Papers_B1hcZZ-AW', 'ICLR_2018_Poster_Papers_B1jscMbAW', 'ICLR_2018_Poster_Papers_B1l8BtlCb', 'ICLR_2018_Poster_Papers_B1mvVm-C-', 'ICLR_2018_Poster_Papers_B1n8LexRZ', 'ICLR_2018_Poster_Papers_B1nZ1weCZ', 'ICLR_2018_Poster_Papers_B1zlp1bRW', 'ICLR_2018_Poster_Papers_BJ0hF1Z0b', 'ICLR_2018_Poster_Papers_BJ8c3f-0b', 'ICLR_2018_Poster_Papers_BJE-4xW0W', 'ICLR_2018_Poster_Papers_BJGWO9k0Z', 'ICLR_2018_Poster_Papers_BJIgi_eCZ', 'ICLR_2018_Poster_Papers_BJJLHbb0-', 'ICLR_2018_Poster_Papers_BJNRFNlRW', 'ICLR_2018_Poster_Papers_BJQRKzbA-', 'ICLR_2018_Poster_Papers_BJRZzFlRb', 'ICLR_2018_Poster_Papers_BJ_UL-k0b', 'ICLR_2018_Poster_Papers_BJ_wN01C-', 'ICLR_2018_Poster_Papers_BJehNfW0-', 'ICLR_2018_Poster_Papers_BJij4yg0Z', 'ICLR_2018_Poster_Papers_BJj6qGbRW', 'ICLR_2018_Poster_Papers_BJk59JZ0b', 'ICLR_2018_Poster_Papers_BJk7Gf-CZ', 'ICLR_2018_Poster_Papers_BJuWrGW0Z', 'ICLR_2018_Poster_Papers_Bk8ZcAxR-', 'ICLR_2018_Poster_Papers_Bk9zbyZCZ', 'ICLR_2018_Poster_Papers_BkJ3ibb0-', 'ICLR_2018_Poster_Papers_BkLhaGZRW', 'ICLR_2018_Poster_Papers_BkN_r2lR-', 'ICLR_2018_Poster_Papers_BkQqq0gRb', 'ICLR_2018_Poster_Papers_BkSDMA36Z', 'ICLR_2018_Poster_Papers_BkUHlMZ0b', 'ICLR_2018_Poster_Papers_BkUp6GZRW', 'ICLR_2018_Poster_Papers_BkXmYfbAZ', 'ICLR_2018_Poster_Papers_BkabRiQpb', 'ICLR_2018_Poster_Papers_BkpiPMbA-', 'ICLR_2018_Poster_Papers_BkrSv0lA-', 'ICLR_2018_Poster_Papers_BkrsAzWAb', 'ICLR_2018_Poster_Papers_BkwHObbRZ', 'ICLR_2018_Poster_Papers_By-7dz-AZ', 'ICLR_2018_Poster_Papers_By4HsfWAZ', 'ICLR_2018_Poster_Papers_ByBAl2eAZ', 'ICLR_2018_Poster_Papers_ByJHuTgA-', 'ICLR_2018_Poster_Papers_ByKWUeWA-', 'ICLR_2018_Poster_Papers_ByOExmWAb', 'ICLR_2018_Poster_Papers_ByOfBggRZ', 'ICLR_2018_Poster_Papers_ByOnmlWC-', 'ICLR_2018_Poster_Papers_ByQpn1ZA-', 'ICLR_2018_Poster_Papers_ByRWCqvT-', 'ICLR_2018_Poster_Papers_ByS1VpgRZ', 'ICLR_2018_Poster_Papers_BySRH6CpW', 'ICLR_2018_Poster_Papers_BydLzGb0Z', 'ICLR_2018_Poster_Papers_BydjJte0-', 'ICLR_2018_Poster_Papers_ByeqORgAW', 'ICLR_2018_Poster_Papers_ByrZyglCb', 'ICLR_2018_Poster_Papers_Bys4ob-Rb', 'ICLR_2018_Poster_Papers_Byt3oJ-0W', 'ICLR_2018_Poster_Papers_BywyFQlAW', 'ICLR_2018_Poster_Papers_H135uzZ0-', 'ICLR_2018_Poster_Papers_H15odZ-C-', 'ICLR_2018_Poster_Papers_H196sainb', 'ICLR_2018_Poster_Papers_H1BLjgZCb', 'ICLR_2018_Poster_Papers_H1Dy---0Z', 'ICLR_2018_Poster_Papers_H1MczcgR-', 'ICLR_2018_Poster_Papers_H1T2hmZAb', 'ICLR_2018_Poster_Papers_H1UOm4gA-', 'ICLR_2018_Poster_Papers_H1VGkIxRZ', 'ICLR_2018_Poster_Papers_H1VjBebR-', 'ICLR_2018_Poster_Papers_H1WgVz-AZ', 'ICLR_2018_Poster_Papers_H1Xw62kRZ', 'ICLR_2018_Poster_Papers_H1Y8hhg0b', 'ICLR_2018_Poster_Papers_H1Yp-j1Cb', 'ICLR_2018_Poster_Papers_H1aIuk-RW', 'ICLR_2018_Poster_Papers_H1cWzoxA-', 'ICLR_2018_Poster_Papers_H1dh6Ax0Z', 'ICLR_2018_Poster_Papers_H1kG7GZAW', 'ICLR_2018_Poster_Papers_H1mCp-ZRZ', 'ICLR_2018_Poster_Papers_H1meywxRW', 'ICLR_2018_Poster_Papers_H1q-TM-AW', 'ICLR_2018_Poster_Papers_H1sUHgb0Z', 'ICLR_2018_Poster_Papers_H1uR4GZRZ', 'ICLR_2018_Poster_Papers_H1vEXaxA-', 'ICLR_2018_Poster_Papers_H1zriGeCZ', 'ICLR_2018_Poster_Papers_HJ94fqApW', 'ICLR_2018_Poster_Papers_HJCXZQbAZ', 'ICLR_2018_Poster_Papers_HJJ23bW0b', 'ICLR_2018_Poster_Papers_HJcSzz-CZ', 'ICLR_2018_Poster_Papers_HJewuJWCZ', 'ICLR_2018_Poster_Papers_HJzgZ3JCW', 'ICLR_2018_Poster_Papers_Hk0wHx-RW', 'ICLR_2018_Poster_Papers_Hk3ddfWRW', 'ICLR_2018_Poster_Papers_Hk5elxbRW', 'ICLR_2018_Poster_Papers_Hk6WhagRW', 'ICLR_2018_Poster_Papers_Hk8XMWgRb', 'ICLR_2018_Poster_Papers_HkAClQgA-', 'ICLR_2018_Poster_Papers_HkCsm6lRb', 'ICLR_2018_Poster_Papers_HkMvEOlAb', 'ICLR_2018_Poster_Papers_HkNGsseC-', 'ICLR_2018_Poster_Papers_HkTEFfZRb', 'ICLR_2018_Poster_Papers_HkUR_y-RZ', 'ICLR_2018_Poster_Papers_HkZy-bW0-', 'ICLR_2018_Poster_Papers_Hkc-TeZ0W', 'ICLR_2018_Poster_Papers_HkgNdt26Z', 'ICLR_2018_Poster_Papers_Hkn7CBaTW', 'ICLR_2018_Poster_Papers_Hko85plCW', 'ICLR_2018_Poster_Papers_HktJec1RZ', 'ICLR_2018_Poster_Papers_HktRlUlAZ', 'ICLR_2018_Poster_Papers_HkuGJ3kCb', 'ICLR_2018_Poster_Papers_HkwBEMWCZ', 'ICLR_2018_Poster_Papers_HkwVAXyCW', 'ICLR_2018_Poster_Papers_HkxF5RgC-', 'ICLR_2018_Poster_Papers_Hy6GHpkCW', 'ICLR_2018_Poster_Papers_HyH9lbZAW', 'ICLR_2018_Poster_Papers_HyRVBzap-', 'ICLR_2018_Poster_Papers_HyRnez-RW', 'ICLR_2018_Poster_Papers_HyUNwulC-', 'ICLR_2018_Poster_Papers_HyWrIgW0W', 'ICLR_2018_Poster_Papers_HyfHgI6aW', 'ICLR_2018_Poster_Papers_Hyg0vbWC-', 'ICLR_2018_Poster_Papers_HyiAuyb0b', 'ICLR_2018_Poster_Papers_HyrCWeWCb', 'ICLR_2018_Poster_Papers_Skz_WfbCZ', 'ICLR_2018_Poster_Papers_Skz_WfbCZ', 'ICLR_2018_Poster_Papers_Sy21R9JAW', 'ICLR_2018_Poster_Papers_SyJS-OgR-', 'ICLR_2018_Poster_Papers_SyMvJrdaW', 'ICLR_2018_Poster_Papers_SyProzZAW', 'ICLR_2018_Poster_Papers_Syhr6pxCW', 'ICLR_2018_Poster_Papers_SyqShMZRb', 'ICLR_2018_Poster_Papers_SysEexbRb']\n",
            "Current ID range 318 to 323\n",
            "ICLR_2018\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# with open(os.path.join(base_dir, 'embeddings_ICLR_2018_test1.pkl'), 'wb') as f:\n",
        "#     pkl.dump(final_papers, f)"
      ],
      "metadata": {
        "id": "sDyfRYf59uDl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "jHageGN5sh_d"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}
